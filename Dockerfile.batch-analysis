# syntax=docker/dockerfile:1.4
#
# AWS Batch Analysis Jobs Dockerfile
# Optimized for running analysis jobs (CET, Fiscal, PaECTER) in AWS Batch
#
# OPTIMIZATION:
# - Uses pre-built r-base image with R and stateio already installed (~10-15 min saved)
# - PaECTER uses HuggingFace API mode (no torch, ~2GB smaller image)
#
# Cache sharing: Uses unified GHA cache scope "sbir-python-deps" shared with CI workflow
#
# Usage:
#   docker build -f Dockerfile.batch-analysis -t sbir-analytics-analysis-jobs:latest .
#
ARG PYTHON_VERSION=3.11.9
ARG R_BASE_IMAGE=ghcr.io/hollomancer/sbir-analytics-r-base:latest

########################################################################
# R Base stage: pre-built image with R + stateio (from build-r-base.yml)
########################################################################
FROM ${R_BASE_IMAGE} AS r-base

########################################################################
# Python dependencies stage: build wheels (shared cache with CI)
########################################################################
FROM python:${PYTHON_VERSION}-slim-bookworm AS python-deps

ARG UV_VERSION=0.5.11

ENV PIP_NO_CACHE_DIR=1 \
    PYTHONUNBUFFERED=1 \
    DEBIAN_FRONTEND=noninteractive

WORKDIR /workspace

# Install minimal build dependencies for Python wheels
RUN --mount=type=cache,target=/var/cache/apt,sharing=locked \
    --mount=type=cache,target=/var/lib/apt,sharing=locked \
    apt-get update && apt-get install -y --no-install-recommends \
    build-essential \
    curl \
    ca-certificates \
    git \
    gcc \
    libpq-dev \
    python3-dev \
    && rm -rf /var/lib/apt/lists/*

# Install UV
RUN curl -LsSf https://astral.sh/uv/${UV_VERSION}/install.sh | sh && \
    mv /root/.local/bin/uv /usr/local/bin/uv

# Copy dependency files
COPY pyproject.toml uv.lock* README.md MANIFEST.in /workspace/

# Build Python wheels (cache shared via GHA scope "sbir-python-deps")
RUN --mount=type=cache,target=/root/.cache/uv \
    --mount=type=cache,target=/root/.cache/pip \
    mkdir -p /wheels \
    && python -m pip install --upgrade pip setuptools wheel \
    && uv export --extra r --no-hashes --no-editable --format requirements-txt -o requirements.txt \
    && sed -i '/^\.$/d' requirements.txt \
    && RPY2_CFFI_MODE=ABI python -m pip wheel --wheel-dir=/wheels -r requirements.txt

########################################################################
# Builder stage: build application wheel
########################################################################
FROM python-deps AS builder

COPY . /workspace/

RUN --mount=type=cache,target=/root/.cache/pip \
    python -m pip wheel --wheel-dir=/wheels .

########################################################################
# Runtime stage: combine R base + Python wheels
########################################################################
FROM ${R_BASE_IMAGE} AS runtime

ENV PATH=/usr/local/bin:$PATH \
    PYTHONUNBUFFERED=1 \
    PIP_NO_CACHE_DIR=1 \
    DAGSTER_HOME=/tmp/dagster_home \
    DAGSTER_LOAD_HEAVY_ASSETS=true

WORKDIR /app

# Install Python wheels from builder stage
COPY --from=builder /wheels /wheels
COPY scripts/docker/dedupe_wheels.py /tmp/dedupe_wheels.py
RUN python3 /tmp/dedupe_wheels.py && pip install --no-cache-dir /wheels/*.whl && rm -rf /wheels /tmp/dedupe_wheels.py

# Copy application code
COPY src/ /app/src/
COPY config/ /app/config/
COPY pyproject.toml /app/

# Create dagster home directory
RUN mkdir -p /tmp/dagster_home

# Verify installations
RUN python -c "import dagster; print(f'Dagster {dagster.__version__}')" && \
    python -c "from src.definitions_ml import auto_jobs; print(f'ML jobs: {list(auto_jobs.keys())}')" && \
    R -e "library(stateior); cat('stateior loaded successfully\n')"

# Default command runs CET pipeline (can be overridden by Batch job definition)
CMD ["dagster", "job", "execute", "-m", "src.definitions_ml", "-j", "cet_full_pipeline_job"]
