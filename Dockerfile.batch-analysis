# syntax=docker/dockerfile:1.4
#
# AWS Batch Analysis Jobs Dockerfile
# Optimized for running analysis jobs (CET, Fiscal, PaECTER) in AWS Batch
#
# OPTIMIZATION: Uses pre-built r-base image with R and stateio already installed
# This saves ~10-15 minutes of R package compilation time per build.
#
# Cache sharing: Uses unified GHA cache scope "sbir-python-deps" shared with CI workflow
#
# Usage:
#   docker build -f Dockerfile.batch-analysis -t sbir-analytics-analysis-jobs:latest .
#
ARG PYTHON_VERSION=3.11.9
ARG R_BASE_IMAGE=ghcr.io/hollomancer/sbir-analytics-r-base:latest

########################################################################
# R Base stage: pre-built image with R + stateio (from build-r-base.yml)
########################################################################
FROM ${R_BASE_IMAGE} AS r-base

########################################################################
# Python dependencies stage: build wheels (shared cache with CI)
########################################################################
FROM python:${PYTHON_VERSION}-slim-bookworm AS python-deps

ARG UV_VERSION=0.5.11

ENV PIP_NO_CACHE_DIR=1 \
    PYTHONUNBUFFERED=1 \
    DEBIAN_FRONTEND=noninteractive

WORKDIR /workspace

# Install minimal build dependencies for Python wheels
RUN --mount=type=cache,target=/var/cache/apt,sharing=locked \
    --mount=type=cache,target=/var/lib/apt,sharing=locked \
    apt-get update && apt-get install -y --no-install-recommends \
    build-essential \
    curl \
    ca-certificates \
    git \
    gcc \
    libpq-dev \
    python3-dev \
    && rm -rf /var/lib/apt/lists/*

# Install UV
RUN curl -LsSf https://astral.sh/uv/${UV_VERSION}/install.sh | sh && \
    mv /root/.local/bin/uv /usr/local/bin/uv

# Copy dependency files
COPY pyproject.toml uv.lock* README.md MANIFEST.in /workspace/

# Build Python wheels (cache shared via GHA scope "sbir-python-deps")
RUN --mount=type=cache,target=/root/.cache/uv \
    --mount=type=cache,target=/root/.cache/pip \
    mkdir -p /wheels \
    && python -m pip install --upgrade pip setuptools wheel \
    && uv export --extra r --extra paecter-local --no-hashes --no-editable --format requirements-txt -o requirements.txt \
    && sed -i '/^\.$/d' requirements.txt \
    && RPY2_CFFI_MODE=ABI python -m pip wheel --wheel-dir=/wheels -r requirements.txt

########################################################################
# Builder stage: build application wheel
########################################################################
FROM python-deps AS builder

COPY . /workspace/

RUN --mount=type=cache,target=/root/.cache/pip \
    python -m pip wheel --wheel-dir=/wheels .

########################################################################
# Runtime stage: combine R base + Python wheels
########################################################################
FROM ${R_BASE_IMAGE} AS runtime

ENV PATH=/usr/local/bin:$PATH \
    PYTHONUNBUFFERED=1 \
    PIP_NO_CACHE_DIR=1 \
    DAGSTER_HOME=/tmp/dagster_home \
    DAGSTER_LOAD_HEAVY_ASSETS=true

WORKDIR /app

# Install Python wheels from builder stage
COPY --from=builder /wheels /wheels

# Deduplicate wheels: keep only the latest version of each package
RUN python3 -c "
import re
from pathlib import Path
from collections import defaultdict
from packaging.version import parse as parse_version

wheels_dir = Path('/wheels')
packages = defaultdict(list)

for wheel in wheels_dir.glob('*.whl'):
    match = re.match(r'^([a-zA-Z0-9_]+)-([0-9.]+[a-zA-Z0-9.]*)-', wheel.name)
    if match:
        pkg_name = match.group(1).lower().replace('_', '-')
        version = match.group(2)
        packages[pkg_name].append((version, wheel))

for pkg_name, versions in packages.items():
    if len(versions) > 1:
        versions.sort(key=lambda x: parse_version(x[0]), reverse=True)
        for _, wheel_path in versions[1:]:
            print(f'Removing duplicate: {wheel_path.name}')
            wheel_path.unlink()
"

RUN pip install --no-cache-dir /wheels/*.whl && rm -rf /wheels

# Copy application code
COPY src/ /app/src/
COPY config/ /app/config/
COPY pyproject.toml /app/

# Create dagster home directory
RUN mkdir -p /tmp/dagster_home

# Verify installations
RUN python -c "import dagster; print(f'Dagster {dagster.__version__}')" && \
    python -c "from src.definitions_ml import auto_jobs; print(f'ML jobs: {list(auto_jobs.keys())}')" && \
    R -e "library(stateior); cat('stateior loaded successfully\n')"

# Default command runs CET pipeline (can be overridden by Batch job definition)
CMD ["dagster", "job", "execute", "-m", "src.definitions_ml", "-j", "cet_full_pipeline_job"]
