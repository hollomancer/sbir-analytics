# sbir-etl/config/envs/prod.yaml
#
# Production environment configuration template for the SBIR ETL pipeline with CET extensions.
# This file provides opinionated overrides and examples for running CET assets and the broader
# pipeline in a production-like environment. Secrets (API keys, DB passwords) MUST be provided
# via environment variables, not committed here.
#
# How to use:
# - Keep defaults in config/base.yaml under version control
# - Layer this file as environment-specific overrides (e.g., via your deployment tooling)
# - Provide secrets using environment variables (see notes in sections below)
#
# Notes:
# - Paths are relative to the repository root by default. In containerized deployments, bind
#   mount volumes to persist data/artifacts (e.g., /app/data, /app/artifacts, /app/reports).
# - CET assets primarily use config in config/cet/taxonomy.yaml and config/cet/classification.yaml.
#   This file centralizes environment and runtime overrides (paths, batch sizes, schedules).
# - Neo4j credentials are read from environment variables to avoid storing secrets in git.

pipeline:
  name: "sbir-etl"
  version: "1.0.0"
  environment: "production"

paths:
  # Adjust these if your deployment uses different mount points
  root: "."
  data_dir: "data"
  raw_dir: "data/raw"
  processed_dir: "data/processed"
  loaded_dir: "data/loaded"
  artifacts_dir: "artifacts"
  reports_dir: "reports"
  logs_dir: "logs"

logging:
  level: "INFO"        # INFO for prod; use DEBUG temporarily for incident investigation
  format: "json"       # "json" recommended for prod ingestion into log aggregators
  file_path: "logs/sbir-etl.log"
  max_file_size_mb: 200
  backup_count: 10
  include_stage: true
  include_run_id: true
  include_timestamps: true

metrics:
  enabled: true
  collection_interval_seconds: 30
  persist_to_file: true
  metrics_file_path: "logs/metrics.json"
  warning_thresholds:
    stage_duration_seconds: 1800     # tighter warning window for prod
    memory_usage_mb: 4096
    error_rate_percentage: 1.0

duckdb:
  # Persist DuckDB database in prod for analytics and ad-hoc queries
  database_path: "data/processed/sbir.duckdb"
  memory_limit_gb: 8
  threads: -1                  # Use all available cores
  enable_object_cache: true
  enable_query_profiler: false

data_quality:
  # Tighten quality thresholds in prod vs base.yaml
  sbir_awards:
    pass_rate_threshold: 0.98
    completeness_threshold: 0.95
    uniqueness_threshold: 0.995
  uspto_patents:
    pass_rate_threshold: 0.995
    completeness_threshold: 0.98
    uniqueness_threshold: 0.995
  completeness:
    award_id: 1.00
    company_name: 0.98
    award_amount: 0.95
    award_date: 0.98
    program: 0.99
  uniqueness:
    award_id: 1.00
  validity:
    award_amount_min: 0.0
    award_amount_max: 5000000.0
    award_year_min: 1983
    award_year_max: 2030
  enrichment:
    sam_gov_success_rate: 0.90
    usaspending_match_rate: 0.80
    regression_threshold_percent: 3.0   # alert on >3pp decline in prod

enrichment:
  performance:
    chunk_size: 50000
    memory_threshold_mb: 4096
    timeout_seconds: 600
    retry_backoff: exponential
    high_confidence_threshold: 92
    low_confidence_threshold: 80
    enable_fuzzy_matching: true
    enable_memory_monitoring: true
    enable_progress_tracking: true
    duration_warning_seconds: 2.0
    memory_delta_warning_mb: 750.0
    memory_pressure_warn_percent: 80.0
    memory_pressure_critical_percent: 95.0

extraction:
  sbir:
    csv_path: "data/raw/sbir/awards_data.csv"
    duckdb:
      database_path: "data/processed/sbir.duckdb"
      table_name: "sbir_awards"
    batch_size: 25000
    encoding: "utf-8"
  usaspending:
    database_name: "usaspending"
    table_name: "awards"
    import_chunk_size: 75000
  uspto:
    csv_path: "data/raw/uspto/patent_assignments.csv"
    batch_size: 10000
    encoding: "utf-8"
    sample_limit: null
    quality:
      min_fields_required: 8
      max_malformed_percentage: 0.005
    transform_output_dir: "data/transformed/uspto"
    transform_batch_size: 2000
    normalize_entity_names: true
    detect_conveyances: true

validation:
  strict_schema: true
  fail_on_first_error: false
  sample_size_for_checks: 5000
  max_error_percentage: 0.01

transformation:
  company_deduplication:
    similarity_threshold: 0.90
    min_company_name_length: 3
  award_normalization:
    currency: "USD"
    standardize_program_names: true
    program_mappings:
      "SBIR": "SBIR"
      "STTR": "STTR"
      "SBIR/STTR": "SBIR/STTR"
  graph_preparation:
    batch_size: 2000
    relationship_types:
      - "AWARDED_TO"
      - "FUNDED_BY"
      - "SUBMITTED_BY"

loading:
  neo4j:
    # Secrets configured via environment variables; do NOT hard-code here.
    # Expected env vars:
    #   NEO4J_URI=bolt://host:7687
    #   NEO4J_USER=neo4j
    #   NEO4J_PASSWORD=********
    #   NEO4J_DATABASE=neo4j                 (optional, defaults to 'neo4j')
    uri_env_var: "NEO4J_URI"
    user_env_var: "NEO4J_USER"
    password_env_var: "NEO4J_PASSWORD"
    database: "${NEO4J_DATABASE:-neo4j}"    # Optional override via environment variable
    output_dir: "data/loaded/neo4j"
    load_success_threshold: 0.995
    create_indexes: true
    create_constraints: true
    batch_operations: true
    batch_size: 2000
    parallel_threads: 8
    transaction_timeout_seconds: 300
    retry_on_deadlock: true
    max_deadlock_retries: 5

# CET-specific operational settings (environment/runtime oriented).
# Core model hyperparameters are defined in config/cet/classification.yaml.
cet:
  taxonomy:
    taxonomy_file: "config/cet/taxonomy.yaml"
    classification_file: "config/cet/classification.yaml"
  model:
    # Model artifact path can be overridden by CET_MODEL_PATH env var at runtime.
    artifact_path: "${CET_MODEL_PATH:-artifacts/models/cet_classifier_v1.pkl}"
  classification:
    # Runtime batch tuning for prod; underlying thresholds remain in classification.yaml
    batch_size: 2000
    parallel_workers: -1   # -1 uses all cores
  evidence:
    # These should match (or be stricter than) config/cet/classification.yaml
    spacy_model: "en_core_web_sm"
    excerpt_max_words: 50
    min_keyword_matches: 1
  analytics:
    use_duckdb: true
    duckdb_threads: -1
    duckdb_memory_limit: "8GB"

# Dagster job and asset configuration examples for production runs.
# These snippets can be copied into Dagster run config when materializing jobs.
dagster:
  schedules:
    # Recommended schedules (UTC); adjust for your environment
    etl_job: "0 2 * * *"          # Full ETL at 02:00 UTC daily
    cet_drift_job: "0 6 * * *"    # CET drift detection at 06:00 UTC daily
  jobs:
    - name: "cet_full_pipeline_job"
      enabled: true
      # Asset-level config overrides (optional). Copy into run config as needed.
      assets:
        neo4j_cetarea_nodes:
          config:
            taxonomy_parquet: "data/processed/cet_taxonomy.parquet"
            taxonomy_json: "data/processed/cet_taxonomy.json"
            create_constraints: true
            create_indexes: true
            batch_size: 2000
        neo4j_award_cet_enrichment:
          config:
            classifications_parquet: "data/processed/cet_award_classifications.parquet"
            classifications_json: "data/processed/cet_award_classifications.json"
            batch_size: 2000
        neo4j_company_cet_enrichment:
          config:
            profiles_parquet: "data/processed/cet_company_profiles.parquet"
            profiles_json: "data/processed/cet_company_profiles.json"
            key_property: "uei"     # can be "company_id" if that matches your graph keys
            batch_size: 2000
        neo4j_award_cet_relationships:
          config:
            classifications_parquet: "data/processed/cet_award_classifications.parquet"
            classifications_json: "data/processed/cet_award_classifications.json"
            rel_type: "APPLICABLE_TO"
            batch_size: 2000
        neo4j_company_cet_relationships:
          config:
            profiles_parquet: "data/processed/cet_company_profiles.parquet"
            profiles_json: "data/processed/cet_company_profiles.json"
            key_property: "uei"
            rel_type: "SPECIALIZES_IN"
            batch_size: 2000

# Environment variable hints (documenting, not applied by YAML):
# - CET_MODEL_PATH: override path to the trained CET classifier artifact
# - SBIR_ETL__CET__SAMPLE_SIZE: sampling size for cet_human_sampling (default 50)
# - SBIR_ETL__CET__SAMPLE_SEED: RNG seed for reproducible sampling (default 42)
#
# Deployment checklist (high level, see docs/deployment for full procedure):
# - Ensure NEO4J_* environment variables are set and reachable from the runtime
# - Mount persistent volumes for data/, reports/, artifacts/, and logs/
# - Verify config/cet/taxonomy.yaml and classification.yaml are present and versioned
# - Bake or mount the model artifact into artifacts/models/ (or set CET_MODEL_PATH)
# - Materialize cet_taxonomy, then run cet_full_pipeline_job
# - Monitor reports/alerts and data/processed/*.checks.json for regressions/failures
