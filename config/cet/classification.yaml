# CET Classification Configuration
# ML model hyperparameters and classification settings

# Model version tracking
model_version: "v1.0.0"
created_date: "2025-01-15"

# Confidence thresholds for classification levels
confidence_thresholds:
  high: 70.0  # High confidence: score >= 70
  medium: 40.0  # Medium confidence: 40 <= score < 70
  low: 0.0  # Low confidence: score < 40

# TF-IDF Vectorization parameters
tfidf:
  max_features: 5000  # Maximum number of features
  min_df: 2  # Minimum document frequency
  max_df: 0.95  # Maximum document frequency (ignore very common terms)
  ngram_range: [1, 2]  # Unigrams and bigrams
  sublinear_tf: true  # Apply sublinear TF scaling (1 + log(tf))
  use_idf: true  # Enable inverse document frequency weighting
  smooth_idf: true  # Smooth IDF weights
  norm: "l2"  # L2 normalization

  # Keyword boosting (increase weight for CET-specific keywords)
  keyword_boost_factor: 2.0  # Multiply TF-IDF score by this factor for CET keywords

  # Stop words (generic SBIR/proposal terms to filter)
  stop_words:
    # Generic SBIR terms
    - "phase"
    - "sbir"
    - "sttr"
    - "award"
    - "contract"
    - "proposal"
    - "program"
    - "project"
    - "research"
    - "development"
    - "technology"
    - "technical"
    # Business terms
    - "company"
    - "firm"
    - "small"
    - "business"
    - "innovative"
    - "innovation"
    # Proposal boilerplate
    - "objective"
    - "approach"
    - "anticipated"
    - "benefits"
    - "commercial"
    - "applications"
    - "potential"
    - "proposed"
    - "develop"
    - "provide"

# Logistic Regression parameters
logistic_regression:
  penalty: "l2"  # L2 regularization
  C: 1.0  # Inverse regularization strength
  solver: "lbfgs"  # Optimization algorithm
  max_iter: 1000  # Maximum iterations
  multi_class: "ovr"  # One-vs-Rest for multi-label classification
  class_weight: "balanced"  # Handle imbalanced CET categories
  random_state: 42  # For reproducibility
  n_jobs: -1  # Use all CPU cores

# Probability Calibration
calibration:
  method: "sigmoid"  # Sigmoid (Platt scaling) calibration
  cv: 3  # 3-fold cross-validation

# Feature Selection
feature_selection:
  enabled: true
  method: "chi2"  # Chi-squared feature selection
  k_best: 3000  # Select top 3000 features

# Evidence Extraction
evidence:
  max_statements: 3  # Maximum evidence statements per classification
  excerpt_max_words: 50  # Maximum words per excerpt
  min_keyword_matches: 1  # Minimum CET keyword matches to include as evidence
  source_priority:  # Priority order for selecting evidence sources
    - "abstract"
    - "keywords"
    - "solicitation"
    - "title"

  # spaCy configuration for sentence segmentation
  spacy:
    model: "en_core_web_sm"  # English model
    disable:  # Disable unnecessary components for performance
      - "ner"
      - "parser"
    enable:
      - "sentencizer"  # Fast sentence segmentation

# Supporting CET Areas
supporting:
  max_supporting_areas: 3  # Maximum supporting CET areas per entity
  min_score_threshold: 40.0  # Minimum score to include as supporting area
  min_score_difference: 5.0  # Minimum score difference from primary to include

# Batch Processing
batch:
  size: 1000  # Process 1000 awards per batch
  parallel_workers: -1  # Use all CPU cores (set to specific number if needed)

# Performance Targets (for monitoring)
performance:
  target_throughput: 1000  # awards/second
  target_latency: 1.0  # seconds per award

# Quality Metrics Targets
quality:
  min_success_rate: 0.95  # 95% classification success rate
  min_high_confidence_rate: 0.60  # 60% high confidence classifications
  min_evidence_coverage: 0.80  # 80% of classifications have evidence

# Agency/Branch Priors (contextual score adjustments)
# These boost classification scores based on known agency/branch focus areas
# Applied additively after ML scoring: final_score = ml_score + agency_boost + branch_boost
priors:
  enabled: true

  # Agency-level priors (boost scores for CETs when awards are funded by specific agencies)
  agencies:
    "Department of Defense":
      hypersonics: 15
      autonomous_systems: 15
      directed_energy: 15
      advanced_engineering_materials: 10
      integrated_sensing_and_cyber: 10
      semiconductors_and_microelectronics: 10
      communication_and_networking_technologies: 10

    "Department of Health and Human Services":
      biotechnologies: 20
      artificial_intelligence: 5  # For medical AI

    "National Aeronautics and Space Administration":
      space_technologies_and_systems: 25
      advanced_engineering_materials: 15
      autonomous_systems: 10
      renewable_energy_generation_and_storage: 10

    "Department of Energy":
      renewable_energy_generation_and_storage: 20
      advanced_nuclear_energy_systems: 20
      quantum_information_science: 15
      advanced_engineering_materials: 10
      semiconductors_and_microelectronics: 10

    "National Science Foundation":
      _all_cets: 5  # Baseline boost for all CETs (NSF funds broad research)

    "Department of Agriculture":
      biotechnologies: 15

    "Environmental Protection Agency":
      renewable_energy_generation_and_storage: 15

    "Department of Commerce":
      semiconductors_and_microelectronics: 15
      communication_and_networking_technologies: 15
      quantum_information_science: 10

  # Branch/sub-agency priors (more specific than agency-level)
  # These override/augment agency priors for specific organizational units
  branches:
    "Air Force":
      hypersonics: 20
      space_technologies_and_systems: 15
      autonomous_systems: 15
      directed_energy: 10
      advanced_engineering_materials: 10

    "Navy":
      autonomous_systems: 15
      advanced_engineering_materials: 15
      directed_energy: 10
      integrated_sensing_and_cyber: 10

    "Army":
      autonomous_systems: 15
      integrated_sensing_and_cyber: 15
      advanced_engineering_materials: 10

    "Missile Defense Agency":
      hypersonics: 25
      directed_energy: 20
      space_technologies_and_systems: 15

    "Defense Advanced Research Projects Agency":
      quantum_information_science: 15
      artificial_intelligence: 15
      biotechnologies: 15
      autonomous_systems: 15
      hypersonics: 15
      directed_energy: 15

    "National Institutes of Health":
      biotechnologies: 25
      artificial_intelligence: 10

# Analytics (DuckDB usage)
analytics:
  use_duckdb: true  # Enable DuckDB for analytics queries
  duckdb_memory_limit: "4GB"
  duckdb_threads: -1  # Use all cores

  # Operations that benefit from DuckDB
  enable_for:
    - "company_aggregation"
    - "portfolio_analytics"
    - "uspto_validation"
    - "neo4j_preparation"

  # Operations that should stay in pandas
  disable_for:
    - "ml_classification"
    - "evidence_extraction"
    - "model_training"
