# .env.test.aura - Neo4j Aura Free Testing Configuration
# Copy this file to `.env.test` and fill in your Neo4j Aura Free instance details.
# IMPORTANT: Do NOT commit your real `.env.test` into version control.

# -----------------------
# Neo4j Aura Free Configuration
# -----------------------
# Neo4j Aura Free provides a small, 100,000 node-capped instance for testing.
# Connection URI uses the neo4j+s:// or bolt+s:// protocol for secure connections.

# Neo4j Aura Free Connection Details
# Get these from your Neo4j Aura console: https://console.neo4j.io/
NEO4J_USER=neo4j
NEO4J_PASSWORD=your_aura_password_here

# -----------------------
# Application / runtime
# -----------------------
# Environment mode: Use 'test-aura' to load test-specific configuration
ENVIRONMENT=test-aura

# Keep Python output unbuffered for better logging
PYTHONUNBUFFERED=1

# -----------------------
# SBIR ETL Neo4j Configuration for Aura Free
# -----------------------
# IMPORTANT: Use the full connection URI from your Aura Free instance
# Format: neo4j+s://<instance-id>.databases.neo4j.io
# Example: neo4j+s://1a2b3c4d.databases.neo4j.io
SBIR_ETL__NEO4J__URI=neo4j+s://your-instance-id.databases.neo4j.io

# For Aura, these are extracted from the URI, but can be set explicitly
SBIR_ETL__NEO4J__USERNAME=${NEO4J_USER}
SBIR_ETL__NEO4J__PASSWORD=${NEO4J_PASSWORD}
SBIR_ETL__NEO4J__DATABASE=neo4j

# -----------------------
# Testing Configuration for 100K Node Limit
# -----------------------
# Reduce batch sizes and limit data processing to stay within Aura Free limits
SBIR_ETL__NEO4J__BATCH_SIZE=500
SBIR_ETL__EXTRACTION__SBIR__BATCH_SIZE=1000

# Enable safeguards to prevent exceeding node limits
SBIR_ETL__NEO4J__MAX_NODES=95000  # Leave buffer for relationships and overhead
SBIR_ETL__NEO4J__CHECK_NODE_COUNT=true  # Validate before bulk loads

# -----------------------
# Test Data Sampling
# -----------------------
# Limit data extraction for testing purposes
# Set to null or remove to process all data
SBIR_ETL__EXTRACTION__SAMPLE_LIMIT=5000  # Process only 5000 awards for testing
SBIR_ETL__EXTRACTION__USPTO__SAMPLE_LIMIT=2000  # Limit patent data

# -----------------------
# DuckDB Configuration (In-Memory for Testing)
# -----------------------
SBIR_ETL__DUCKDB__DATABASE_PATH=:memory:
SBIR_ETL__DUCKDB__MEMORY_LIMIT_GB=2
SBIR_ETL__DUCKDB__THREADS=2

# -----------------------
# Logging Configuration
# -----------------------
SBIR_ETL__LOGGING__LEVEL=DEBUG
SBIR_ETL__LOGGING__FORMAT=json
SBIR_ETL__LOGGING__FILE_PATH=logs/test-aura.log

# -----------------------
# Notes
# -----------------------
# Neo4j Aura Free Limitations:
# - 100,000 nodes maximum
# - 200,000 properties maximum
# - 200,000 relationships maximum
# - Storage capped at the above limits
# - Free instances pause after 3 days of inactivity
#
# Best Practices:
# 1. Use sample data limits (SAMPLE_LIMIT) to control data volume
# 2. Monitor node count during pipeline execution
# 3. Clean up test data between runs to stay within limits
# 4. Use the node count validation script before bulk loads
# 5. Consider using constraints and indexes efficiently
#
# Getting Your Aura Free Instance:
# 1. Sign up at https://neo4j.com/cloud/aura-free/
# 2. Create a new free instance
# 3. Copy the connection URI and password
# 4. Update SBIR_ETL__NEO4J__URI and NEO4J_PASSWORD above
