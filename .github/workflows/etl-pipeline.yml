name: ETL Pipeline

on:
  schedule:
    # Weekly full pipeline on Monday at 10 AM UTC
    - cron: "0 10 * * 1"
  workflow_dispatch:
    inputs:
      job:
        description: "Job to run"
        required: true
        type: choice
        options:
          - sbir_ingestion
          - sbir_weekly_refresh  # includes Neo4j loading
          - usaspending_ingestion
          - uspto_pipeline
          - cet_pipeline
          - all
      skip_neo4j:
        description: "Skip Neo4j loading"
        required: false
        default: false
        type: boolean

permissions:
  id-token: write
  contents: read
  packages: read

env:
  AWS_REGION: us-east-2
  S3_BUCKET: sbir-etl-production-data
  SBIR_ETL__PIPELINE__ENVIRONMENT: production
  IMAGE: ghcr.io/hollomancer/sbir-analytics:latest

jobs:
  sbir-pipeline:
    name: SBIR Pipeline
    if: github.event.inputs.job == 'sbir_ingestion' || github.event.inputs.job == 'sbir_weekly_refresh' || github.event.inputs.job == 'all' || github.event_name == 'schedule'
    runs-on: ubuntu-latest
    timeout-minutes: 30
    container:
      image: ghcr.io/hollomancer/sbir-analytics:latest
      credentials:
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
    steps:
      - uses: actions/checkout@v6

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Download data from S3
        env:
          S3_BUCKET: ${{ env.S3_BUCKET }}
        shell: bash
        run: |
          echo "ðŸ“¥ Downloading data from S3..."
          mkdir -p data/raw/sbir data/raw/sam_gov data/usaspending

          # Download latest SBIR awards
          LATEST_SBIR=$(aws s3 ls "s3://${S3_BUCKET}/raw/awards/" --recursive | sort | tail -1 | awk '{print $4}')
          if [ -n "$LATEST_SBIR" ]; then
            aws s3 cp "s3://${S3_BUCKET}/${LATEST_SBIR}" data/raw/sbir/award_data.csv
            echo "âœ… Downloaded SBIR awards"
          fi

          # Download SAM.gov entity data
          aws s3 cp "s3://${S3_BUCKET}/raw/sam_gov/sam_entity_records.parquet" data/raw/sam_gov/sam_entity_records.parquet && echo "âœ… Downloaded SAM.gov entities" || echo "âš ï¸ SAM.gov data not found"

          # Download latest USAspending database (for recipient enrichment)
          LATEST_USA=$(aws s3 ls "s3://${S3_BUCKET}/raw/usaspending/database/" --recursive | grep "\.zip$" | sort | tail -1 | awk '{print $4}')
          if [ -n "$LATEST_USA" ]; then
            aws s3 cp "s3://${S3_BUCKET}/${LATEST_USA}" data/usaspending/usaspending-db.zip
            echo "âœ… Downloaded USAspending database"
          fi

      - name: Run SBIR pipeline
        env:
          NEO4J_URI: ${{ secrets.NEO4J_URI }}
          NEO4J_USER: ${{ secrets.NEO4J_USER }}
          NEO4J_PASSWORD: ${{ secrets.NEO4J_PASSWORD }}
          S3_BUCKET: ${{ env.S3_BUCKET }}
        shell: bash
        run: |
          echo "## ðŸŽ¯ SBIR Pipeline" >> $GITHUB_STEP_SUMMARY

          # Determine which job to run
          if [ "${{ github.event.inputs.job }}" = "sbir_ingestion" ]; then
            JOB_NAME="sbir_ingestion_job"
          else
            JOB_NAME="sbir_weekly_refresh_job"
          fi

          # Skip Neo4j if requested
          if [ "${{ github.event.inputs.skip_neo4j }}" = "true" ]; then
            JOB_NAME="sbir_ingestion_job"
          fi

          echo "Running job: $JOB_NAME"

          dagster job execute \
            -m src.definitions \
            -j "$JOB_NAME" \
            2>&1 | tee sbir_output.txt

          EXIT_CODE=${PIPESTATUS[0]}
          if [ $EXIT_CODE -eq 0 ]; then
            echo "âœ… SBIR pipeline completed" >> $GITHUB_STEP_SUMMARY
          else
            echo "âŒ SBIR pipeline failed" >> $GITHUB_STEP_SUMMARY
            tail -100 sbir_output.txt >> $GITHUB_STEP_SUMMARY
            exit $EXIT_CODE
          fi

  usaspending-pipeline:
    name: USAspending Pipeline
    if: github.event.inputs.job == 'usaspending_ingestion' || github.event.inputs.job == 'all'
    runs-on: ubuntu-latest
    timeout-minutes: 180
    container:
      image: ghcr.io/hollomancer/sbir-analytics:latest
      credentials:
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
    steps:
      - uses: actions/checkout@v6

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Run USAspending pipeline
        env:
          S3_BUCKET: ${{ env.S3_BUCKET }}
        shell: bash
        run: |
          echo "## ðŸ’° USAspending Pipeline" >> $GITHUB_STEP_SUMMARY

          dagster job execute \
            -m src.definitions \
            -j usaspending_ingestion_job \
            2>&1 | tee usaspending_output.txt

          EXIT_CODE=${PIPESTATUS[0]}
          if [ $EXIT_CODE -eq 0 ]; then
            echo "âœ… USAspending pipeline completed" >> $GITHUB_STEP_SUMMARY
          else
            echo "âŒ USAspending pipeline failed" >> $GITHUB_STEP_SUMMARY
            tail -100 usaspending_output.txt >> $GITHUB_STEP_SUMMARY
            exit 1
          fi

  uspto-pipeline:
    name: USPTO Pipeline
    if: github.event.inputs.job == 'uspto_pipeline' || github.event.inputs.job == 'all'
    runs-on: ubuntu-latest
    timeout-minutes: 120
    container:
      image: ghcr.io/hollomancer/sbir-analytics:latest
      credentials:
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
    steps:
      - uses: actions/checkout@v6

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Run USPTO pipeline
        env:
          NEO4J_URI: ${{ secrets.NEO4J_URI }}
          NEO4J_USER: ${{ secrets.NEO4J_USER }}
          NEO4J_PASSWORD: ${{ secrets.NEO4J_PASSWORD }}
          S3_BUCKET: ${{ env.S3_BUCKET }}
        shell: bash
        run: |
          echo "## ðŸ“œ USPTO Pipeline" >> $GITHUB_STEP_SUMMARY

          dagster job execute \
            -m src.definitions \
            -j uspto_full_pipeline_job \
            2>&1 | tee uspto_output.txt

          EXIT_CODE=${PIPESTATUS[0]}
          if [ $EXIT_CODE -eq 0 ]; then
            echo "âœ… USPTO pipeline completed" >> $GITHUB_STEP_SUMMARY
          else
            echo "âŒ USPTO pipeline failed" >> $GITHUB_STEP_SUMMARY
            tail -100 uspto_output.txt >> $GITHUB_STEP_SUMMARY
            exit 1
          fi

  cet-pipeline:
    name: CET Classification Pipeline
    if: github.event.inputs.job == 'cet_pipeline' || github.event.inputs.job == 'all'
    runs-on: ubuntu-latest
    timeout-minutes: 60
    container:
      image: ghcr.io/hollomancer/sbir-analytics:latest
      credentials:
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
    steps:
      - uses: actions/checkout@v6

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Run CET pipeline
        env:
          NEO4J_URI: ${{ secrets.NEO4J_URI }}
          NEO4J_USER: ${{ secrets.NEO4J_USER }}
          NEO4J_PASSWORD: ${{ secrets.NEO4J_PASSWORD }}
          S3_BUCKET: ${{ env.S3_BUCKET }}
        shell: bash
        run: |
          echo "## ðŸ·ï¸ CET Classification Pipeline" >> $GITHUB_STEP_SUMMARY

          dagster job execute \
            -m src.definitions \
            -j cet_full_pipeline_job \
            2>&1 | tee cet_output.txt

          EXIT_CODE=${PIPESTATUS[0]}
          if [ $EXIT_CODE -eq 0 ]; then
            echo "âœ… CET pipeline completed" >> $GITHUB_STEP_SUMMARY
          else
            echo "âŒ CET pipeline failed" >> $GITHUB_STEP_SUMMARY
            tail -100 cet_output.txt >> $GITHUB_STEP_SUMMARY
            exit 1
          fi

  summary:
    name: Pipeline Summary
    needs: [sbir-pipeline, usaspending-pipeline, uspto-pipeline, cet-pipeline]
    if: always()
    runs-on: ubuntu-latest
    steps:
      - name: Generate summary
        run: |
          echo "# ðŸ“Š ETL Pipeline Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Pipeline | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|----------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| SBIR | ${{ needs.sbir-pipeline.result || 'skipped' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| USAspending | ${{ needs.usaspending-pipeline.result || 'skipped' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| USPTO | ${{ needs.uspto-pipeline.result || 'skipped' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| CET | ${{ needs.cet-pipeline.result || 'skipped' }} |" >> $GITHUB_STEP_SUMMARY
