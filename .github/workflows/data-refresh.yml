name: Data Refresh

on:
  schedule:
    # SBIR Awards: Weekly on Monday at 9 AM UTC
    - cron: "0 9 * * 1"
    # USAspending: Monthly on 6th at 2 AM UTC
    - cron: "0 2 6 * *"
    # USPTO: Monthly on 1st at 9 AM UTC
    - cron: "0 9 1 * *"
  workflow_dispatch:
    inputs:
      source:
        description: "Data source to refresh"
        required: true
        type: choice
        options:
          - sbir
          - usaspending
          - uspto
          - all
      environment:
        description: "Neo4j environment"
        required: true
        default: production
        type: choice
        options:
          - production
          - test
      force_refresh:
        description: "Force refresh even if no changes detected"
        required: false
        default: false
        type: boolean
      trigger_dagster:
        description: "Trigger Dagster ETL after data refresh"
        required: false
        default: true
        type: boolean

permissions:
  id-token: write
  contents: read

concurrency:
  group: data-refresh-${{ github.event.inputs.source || 'scheduled' }}
  cancel-in-progress: false

env:
  AWS_REGION: us-east-2
  S3_BUCKET: sbir-etl-production-data

jobs:
  determine-source:
    name: Determine Refresh Source
    runs-on: ubuntu-latest
    timeout-minutes: 5
    outputs:
      sbir: ${{ steps.determine.outputs.sbir }}
      usaspending: ${{ steps.determine.outputs.usaspending }}
      uspto: ${{ steps.determine.outputs.uspto }}
    steps:
      - name: Determine which sources to refresh
        id: determine
        run: |
          # Manual trigger
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            SOURCE="${{ github.event.inputs.source }}"
            if [ "$SOURCE" = "all" ]; then
              echo "sbir=true" >> $GITHUB_OUTPUT
              echo "usaspending=true" >> $GITHUB_OUTPUT
              echo "uspto=true" >> $GITHUB_OUTPUT
            else
              echo "sbir=$([[ $SOURCE == 'sbir' ]] && echo true || echo false)" >> $GITHUB_OUTPUT
              echo "usaspending=$([[ $SOURCE == 'usaspending' ]] && echo true || echo false)" >> $GITHUB_OUTPUT
              echo "uspto=$([[ $SOURCE == 'uspto' ]] && echo true || echo false)" >> $GITHUB_OUTPUT
            fi
          # Scheduled trigger - determine by cron schedule
          else
            CRON_SCHEDULE="${{ github.event.schedule }}"
            case "$CRON_SCHEDULE" in
              "0 9 * * 1")  # Weekly Monday
                echo "sbir=true" >> $GITHUB_OUTPUT
                echo "usaspending=false" >> $GITHUB_OUTPUT
                echo "uspto=false" >> $GITHUB_OUTPUT
                ;;
              "0 2 6 * *")  # Monthly 6th
                echo "sbir=false" >> $GITHUB_OUTPUT
                echo "usaspending=true" >> $GITHUB_OUTPUT
                echo "uspto=false" >> $GITHUB_OUTPUT
                ;;
              "0 9 1 * *")  # Monthly 1st
                echo "sbir=false" >> $GITHUB_OUTPUT
                echo "usaspending=false" >> $GITHUB_OUTPUT
                echo "uspto=true" >> $GITHUB_OUTPUT
                ;;
            esac
          fi

      - name: Generate workflow summary
        run: |
          echo "## ðŸ“Š Data Refresh Plan" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "```mermaid" >> $GITHUB_STEP_SUMMARY
          echo "graph LR" >> $GITHUB_STEP_SUMMARY
          echo "  A[Determine Source] --> B{Which Source?}" >> $GITHUB_STEP_SUMMARY
          if [ "${{ steps.determine.outputs.sbir }}" = "true" ]; then
            echo "  B -->|SBIR| C[Refresh SBIR Awards]" >> $GITHUB_STEP_SUMMARY
          fi
          if [ "${{ steps.determine.outputs.usaspending }}" = "true" ]; then
            echo "  B -->|USAspending| D[Extract Recipients]" >> $GITHUB_STEP_SUMMARY
          fi
          if [ "${{ steps.determine.outputs.uspto }}" = "true" ]; then
            echo "  B -->|USPTO| E[Refresh USPTO Patents]" >> $GITHUB_STEP_SUMMARY
          fi
          echo "```" >> $GITHUB_STEP_SUMMARY

  refresh-sbir:
    name: Refresh SBIR Awards
    needs: determine-source
    if: needs.determine-source.outputs.sbir == 'true'
    runs-on: ubuntu-latest
    timeout-minutes: 15
    permissions:
      id-token: write
      contents: read
    steps:
      - uses: actions/checkout@v6

      - name: Configure AWS credentials
        uses: ./.github/actions/setup-aws-credentials
        with:
          role-arn: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Python and UV
        uses: ./.github/actions/setup-python-uv
        with:
          python-version: "3.11"
          install-dev-deps: "false"

      - name: Check existing SBIR files
        run: |
          echo "## ðŸŽ¯ SBIR Awards Refresh Report" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ“‚ Current SBIR Files in S3" >> $GITHUB_STEP_SUMMARY
          aws s3 ls "s3://${{ env.S3_BUCKET }}/raw/awards/" --recursive --human-readable | tail -10 >> $GITHUB_STEP_SUMMARY || echo "No files found"
          echo "" >> $GITHUB_STEP_SUMMARY

      - name: Download SBIR awards
        env:
          S3_BUCKET: ${{ env.S3_BUCKET }}
        run: |
          echo "### ðŸ“¥ Downloading SBIR Awards" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Install minimal dependencies
          uv pip install boto3 requests

          # Download and upload
          uv run python scripts/data/download_sbir.py 2>&1 | tee sbir_download.log

          echo "<details><summary>Download Log</summary>" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          cat sbir_download.log >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          echo "</details>" >> $GITHUB_STEP_SUMMARY

      - name: Check downloaded files
        if: always()
        run: |
          echo "### ðŸ“¦ SBIR Files After Refresh" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          aws s3 ls "s3://${{ env.S3_BUCKET }}/raw/awards/" --recursive --human-readable | tail -10 >> $GITHUB_STEP_SUMMARY || echo "No files found"

  refresh-usaspending:
    name: Refresh USAspending Recipients
    needs: determine-source
    if: needs.determine-source.outputs.usaspending == 'true'
    runs-on: ubuntu-latest
    timeout-minutes: 15 # Just submits job, doesn't wait
    steps:
      - uses: actions/checkout@v6

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v5
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Python and UV
        uses: ./.github/actions/setup-python-uv
        with:
          python-version: "3.11"
          install-dev-deps: "false"

      - name: Check for new USAspending dump
        id: check-new
        run: |
          echo "## ðŸ” Checking for New USAspending Data" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Find latest dump URL from USAspending
          LATEST_URL=$(uv run python -c "
          import requests
          from datetime import datetime, timedelta

          base_url = 'https://files.usaspending.gov/database_download'
          for days_ago in range(0, 60):  # Extended to 60 days
              date = datetime.now() - timedelta(days=days_ago)
              filename = f'usaspending-db_{date.strftime(\"%Y%m%d\")}.zip'
              url = f'{base_url}/{filename}'
              try:
                  resp = requests.head(url, timeout=5)
                  if resp.status_code == 200:
                      print(url)
                      break
              except:
                  continue
          ")

          if [ -z "$LATEST_URL" ]; then
            echo "âš ï¸ Could not find USAspending dump (URL may have changed)" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY

            # Check if we already have recipient data
            EXISTING=$(aws s3 ls "s3://${{ env.S3_BUCKET }}/raw/usaspending/recipient_lookup/" --recursive | tail -1 || echo "")
            if [ -n "$EXISTING" ]; then
              echo "âœ… Using existing recipient_lookup data in S3" >> $GITHUB_STEP_SUMMARY
              echo "is_new=false" >> $GITHUB_OUTPUT
              exit 0
            else
              echo "âŒ No existing recipient data found" >> $GITHUB_STEP_SUMMARY
              exit 1
            fi
          fi

          # Extract date from URL
          DUMP_DATE=$(echo "$LATEST_URL" | grep -oE '[0-9]{8}')
          echo "latest_url=$LATEST_URL" >> $GITHUB_OUTPUT
          echo "dump_date=$DUMP_DATE" >> $GITHUB_OUTPUT

          echo "**Latest dump:** \`$LATEST_URL\`" >> $GITHUB_STEP_SUMMARY
          echo "**Dump date:** $DUMP_DATE" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Check if we already have both recipient and NAICS data
          RECIPIENT_DATE=$(aws s3 ls "s3://${{ env.S3_BUCKET }}/raw/usaspending/recipient_lookup/" --recursive | grep -oE '[0-9]{4}-[0-9]{2}-[0-9]{2}' | sort -r | head -1 || echo "")
          NAICS_DATE=$(aws s3 ls "s3://${{ env.S3_BUCKET }}/raw/usaspending/naics_lookup/" --recursive | grep -oE '[0-9]{4}-[0-9]{2}-[0-9]{2}' | sort -r | head -1 || echo "")

          echo "**Existing recipient_lookup:** ${RECIPIENT_DATE:-none}" >> $GITHUB_STEP_SUMMARY
          echo "**Existing naics_lookup:** ${NAICS_DATE:-none}" >> $GITHUB_STEP_SUMMARY

          # Skip if both exist and are current
          if [ -n "$RECIPIENT_DATE" ] && [ -n "$NAICS_DATE" ]; then
            RECIPIENT_YYYYMMDD=$(echo "$RECIPIENT_DATE" | tr -d '-')
            NAICS_YYYYMMDD=$(echo "$NAICS_DATE" | tr -d '-')

            if [ "$RECIPIENT_YYYYMMDD" -ge "$DUMP_DATE" ] && [ "$NAICS_YYYYMMDD" -ge "$DUMP_DATE" ] && [ "${{ github.event.inputs.force_refresh }}" != "true" ]; then
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "âœ… Both datasets up to date - skipping extraction" >> $GITHUB_STEP_SUMMARY
              echo "is_new=false" >> $GITHUB_OUTPUT
              exit 0
            fi
          fi

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "ðŸ†• New version available - will extract" >> $GITHUB_STEP_SUMMARY
          echo "is_new=true" >> $GITHUB_OUTPUT

      - name: Submit USAspending extraction job
        if: steps.check-new.outputs.is_new == 'true' || github.event.inputs.force_refresh == 'true'
        run: |
          echo "## ðŸ“¥ Submitting USAspending Extraction Job" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Submitting job to AWS Batch for large file processing..." >> $GITHUB_STEP_SUMMARY
          echo "- recipient_lookup from 5881.dat.gz (~1.2 GB compressed)" >> $GITHUB_STEP_SUMMARY
          echo "- NAICS lookup from 5882.dat.gz (~57 GB compressed)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Submit Batch job
          JOB_ID=$(aws batch submit-job \
            --job-name "usaspending-extract-$(date +%Y%m%d-%H%M%S)" \
            --job-queue sbir-analytics-analysis-job-queue \
            --job-definition sbir-analytics-usaspending-extract \
            --container-overrides "{\"environment\":[{\"name\":\"USASPENDING_URL\",\"value\":\"${{ steps.check-new.outputs.latest_url }}\"}]}" \
            --query 'jobId' \
            --output text)

          echo "**Job ID:** \`$JOB_ID\`" >> $GITHUB_STEP_SUMMARY
          echo "**Job URL:** https://console.aws.amazon.com/batch/home?region=${{ env.AWS_REGION }}#jobs/detail/$JOB_ID" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "â³ Job submitted - will run in background (3-4 hours expected)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Note:** ETL pipeline will validate data availability before processing" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            aws logs get-log-events \
              --log-group-name /aws/batch/sbir-analytics-analysis \
              --log-stream-name "$LOG_STREAM" \
              --query 'events[*].message' \
              --output text >> $GITHUB_STEP_SUMMARY
          fi

          echo '```' >> $GITHUB_STEP_SUMMARY
          echo "</details>" >> $GITHUB_STEP_SUMMARY

          # Extract metrics from logs
          RECIPIENT_COUNT=$(aws logs get-log-events \
            --log-group-name /aws/batch/sbir-analytics-analysis \
            --log-stream-name "$LOG_STREAM" \
            --query 'events[*].message' \
            --output text | grep -oE 'Extracted [0-9,]+ recipients' | grep -oE '[0-9,]+' || echo "unknown")

          NAICS_COUNT=$(aws logs get-log-events \
            --log-group-name /aws/batch/sbir-analytics-analysis \
            --log-stream-name "$LOG_STREAM" \
            --query 'events[*].message' \
            --output text | grep -oE 'Extracted [0-9,]+ unique' | grep -oE '[0-9,]+' || echo "unknown")

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ“Š Results" >> $GITHUB_STEP_SUMMARY
          echo "- **Recipients:** $RECIPIENT_COUNT" >> $GITHUB_STEP_SUMMARY
          echo "- **NAICS pairs:** $NAICS_COUNT" >> $GITHUB_STEP_SUMMARY

          if [ "$STATUS" != "SUCCEEDED" ]; then
            exit 1
          fi

      - name: Report status
        if: always()
        run: |
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### ðŸ“¦ USAspending Files in S3" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**recipient_lookup:**" >> $GITHUB_STEP_SUMMARY
          aws s3 ls "s3://${{ env.S3_BUCKET }}/raw/usaspending/recipient_lookup/" --recursive --human-readable | tail -5 >> $GITHUB_STEP_SUMMARY || echo "No files found"
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**naics_lookup:**" >> $GITHUB_STEP_SUMMARY
          aws s3 ls "s3://${{ env.S3_BUCKET }}/raw/usaspending/naics_lookup/" --recursive --human-readable | tail -5 >> $GITHUB_STEP_SUMMARY || echo "No files found"

  refresh-uspto:
    name: Refresh USPTO Patents
    needs: determine-source
    if: needs.determine-source.outputs.uspto == 'true'
    runs-on: ubuntu-latest
    timeout-minutes: 180
    steps:
      - uses: actions/checkout@v6

      - name: Configure AWS credentials
        uses: ./.github/actions/setup-aws-credentials
        with:
          role-arn: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Python and UV
        uses: ./.github/actions/setup-python-uv
        with:
          python-version: "3.11"
          install-dev-deps: "false"

      - name: Install Playwright
        run: |
          uv pip install playwright
          uv run python -m playwright install chromium

      - name: Download USPTO data
        id: uspto-download
        env:
          S3_BUCKET: ${{ env.S3_BUCKET }}
        run: |
          echo "## ðŸ“¥ USPTO Patent Data Download" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          SUCCESS=true

          # PatentsView (uses direct download - still works)
          echo "### 1ï¸âƒ£ PatentsView Data" >> $GITHUB_STEP_SUMMARY
          uv run python scripts/data/download_uspto.py --dataset patentsview --table patent 2>&1 | tee patentsview.log &
          PID_PV=$!

          # AI Patents (uses direct download - still works)
          echo "### 2ï¸âƒ£ AI Patents" >> $GITHUB_STEP_SUMMARY
          uv run python scripts/data/download_uspto.py --dataset ai_patents 2>&1 | tee ai_patents.log &
          PID_AI=$!

          # Wait for direct downloads
          wait $PID_PV || SUCCESS=false
          wait $PID_AI || SUCCESS=false

          # Patent Assignments - requires browser automation due to USPTO portal changes
          echo "### 3ï¸âƒ£ Patent Assignments (Browser Download)" >> $GITHUB_STEP_SUMMARY
          uv run python scripts/data/download_uspto_browser.py \
            --dataset assignments \
            --upload-s3 \
            --s3-bucket "$S3_BUCKET" \
            2>&1 | tee assignments.log || SUCCESS=false

          # Report results
          for log in patentsview.log ai_patents.log assignments.log; do
            if [ -f "$log" ]; then
              echo "<details><summary>$log</summary>" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
              echo '```' >> $GITHUB_STEP_SUMMARY
              cat $log >> $GITHUB_STEP_SUMMARY
              echo '```' >> $GITHUB_STEP_SUMMARY
              echo "</details>" >> $GITHUB_STEP_SUMMARY
            fi
          done

          if [ "$SUCCESS" = "false" ]; then
            echo "::error::One or more USPTO downloads failed"
            exit 1
          fi

      - name: Verify USPTO assignment files
        env:
          S3_BUCKET: ${{ env.S3_BUCKET }}
        run: |
          echo "## ðŸ“¦ Verifying USPTO Assignment Files" >> $GITHUB_STEP_SUMMARY

          DATE_STR=$(date -u +%Y-%m-%d)

          # The browser download script uploads individual files directly
          # Verify they exist and are valid ZIPs
          echo "Checking uploaded files:" >> $GITHUB_STEP_SUMMARY

          VALID=true
          for file in assignment assignor assignee documentid; do
            S3_PATH="s3://${S3_BUCKET}/raw/uspto/assignments/${DATE_STR}/${file}.csv.zip"

            # Check if file exists
            if aws s3 ls "$S3_PATH" > /dev/null 2>&1; then
              SIZE=$(aws s3 ls "$S3_PATH" | awk '{print $3}')
              SIZE_MB=$((SIZE / 1024 / 1024))

              # Verify it's not too small (HTML pages are ~16KB)
              if [ "$SIZE" -lt 100000 ]; then
                echo "  âŒ $file.csv.zip: ${SIZE_MB}MB (TOO SMALL - may be HTML)" >> $GITHUB_STEP_SUMMARY
                VALID=false
              else
                echo "  âœ… $file.csv.zip: ${SIZE_MB}MB" >> $GITHUB_STEP_SUMMARY
              fi
            else
              echo "  âŒ $file.csv.zip: NOT FOUND" >> $GITHUB_STEP_SUMMARY
              VALID=false
            fi
          done

          if [ "$VALID" = "false" ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "âŒ Some USPTO assignment files are missing or invalid" >> $GITHUB_STEP_SUMMARY
            exit 1
          fi

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "âœ… All USPTO assignment files verified" >> $GITHUB_STEP_SUMMARY

      - name: Check S3 uploads
        if: always()
        run: |
          echo "## ðŸ“¦ USPTO S3 Upload Status" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          for prefix in "raw/uspto/patentsview" "raw/uspto/assignments" "raw/uspto/ai_patents"; do
            echo "### $prefix" >> $GITHUB_STEP_SUMMARY
            aws s3 ls "s3://${{ env.S3_BUCKET }}/$prefix/" --recursive --human-readable | tail -5 >> $GITHUB_STEP_SUMMARY || echo "No files found"
            echo "" >> $GITHUB_STEP_SUMMARY
          done

  summary:
    name: Refresh Summary
    needs: [determine-source, refresh-sbir, refresh-usaspending, refresh-uspto]
    if: always()
    runs-on: ubuntu-latest
    timeout-minutes: 5
    steps:
      - name: Configure AWS credentials
        uses: actions/checkout@v6

      - name: Setup AWS
        uses: ./.github/actions/setup-aws-credentials
        with:
          role-arn: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Generate summary
        run: |
          echo "# ðŸ“Š Data Refresh Workflow Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Workflow Run:** [#${{ github.run_number }}](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})" >> $GITHUB_STEP_SUMMARY
          echo "**Trigger:** ${{ github.event_name }}" >> $GITHUB_STEP_SUMMARY
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            echo "**Requested Source:** ${{ github.event.inputs.source }}" >> $GITHUB_STEP_SUMMARY
            echo "**Force Refresh:** ${{ github.event.inputs.force_refresh }}" >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY

          # Overall status
          OVERALL_SUCCESS=true
          TOTAL=0
          SUCCESS_COUNT=0
          FAILED_COUNT=0
          SKIPPED_COUNT=0

          echo "## ðŸ“‹ Job Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Data Source | Status | Result |" >> $GITHUB_STEP_SUMMARY
          echo "|-------------|--------|--------|" >> $GITHUB_STEP_SUMMARY

          # SBIR
          if [ "${{ needs.determine-source.outputs.sbir }}" = "true" ]; then
            TOTAL=$((TOTAL + 1))
            JOB_STATUS="${{ needs.refresh-sbir.result }}"

            # Check if job succeeded (Step Functions started)
            if [ "$JOB_STATUS" = "success" ]; then
              # Job succeeded, but check execution status from the detailed report
              # The execution status is shown in the SBIR job's own summary
              EMOJI="âœ…"
              SUCCESS_COUNT=$((SUCCESS_COUNT + 1))
              RESULT="Step Functions execution completed - check detailed report above"
            elif [ "$JOB_STATUS" = "failure" ]; then
              EMOJI="âŒ"
              FAILED_COUNT=$((FAILED_COUNT + 1))
              RESULT="Failed to start or complete execution"
              OVERALL_SUCCESS=false
            else
              EMOJI="â­ï¸"
              SKIPPED_COUNT=$((SKIPPED_COUNT + 1))
              RESULT="Skipped or cancelled"
            fi
            echo "| ðŸŽ¯ SBIR Awards | $EMOJI $JOB_STATUS | $RESULT |" >> $GITHUB_STEP_SUMMARY
          else
            echo "| ðŸŽ¯ SBIR Awards | â­ï¸ skipped | Not scheduled for this run |" >> $GITHUB_STEP_SUMMARY
          fi

          # USAspending
          if [ "${{ needs.determine-source.outputs.usaspending }}" = "true" ]; then
            TOTAL=$((TOTAL + 1))
            STATUS="${{ needs.refresh-usaspending.result }}"
            if [ "$STATUS" = "success" ]; then
              EMOJI="âœ…"
              SUCCESS_COUNT=$((SUCCESS_COUNT + 1))
              RESULT="Recipients + NAICS lookup extracted"
            elif [ "$STATUS" = "failure" ]; then
              EMOJI="âŒ"
              FAILED_COUNT=$((FAILED_COUNT + 1))
              RESULT="Extraction failed"
              OVERALL_SUCCESS=false
            else
              EMOJI="â­ï¸"
              SKIPPED_COUNT=$((SKIPPED_COUNT + 1))
              RESULT="Skipped or cancelled"
            fi
            echo "| ðŸ’° USAspending | $EMOJI $STATUS | $RESULT |" >> $GITHUB_STEP_SUMMARY
          else
            echo "| ðŸ’° USAspending | â­ï¸ skipped | Not scheduled for this run |" >> $GITHUB_STEP_SUMMARY
          fi

          # USPTO
          if [ "${{ needs.determine-source.outputs.uspto }}" = "true" ]; then
            TOTAL=$((TOTAL + 1))
            STATUS="${{ needs.refresh-uspto.result }}"
            if [ "$STATUS" = "success" ]; then
              EMOJI="âœ…"
              SUCCESS_COUNT=$((SUCCESS_COUNT + 1))
              RESULT="Patent data downloaded via Lambda"
            elif [ "$STATUS" = "failure" ]; then
              EMOJI="âŒ"
              FAILED_COUNT=$((FAILED_COUNT + 1))
              RESULT="Lambda invocation failed"
              OVERALL_SUCCESS=false
            else
              EMOJI="â­ï¸"
              SKIPPED_COUNT=$((SKIPPED_COUNT + 1))
              RESULT="Skipped or cancelled"
            fi
            echo "| ðŸ“œ USPTO Patents | $EMOJI $STATUS | $RESULT |" >> $GITHUB_STEP_SUMMARY
          else
            echo "| ðŸ“œ USPTO Patents | â­ï¸ skipped | Not scheduled for this run |" >> $GITHUB_STEP_SUMMARY
          fi

          echo "" >> $GITHUB_STEP_SUMMARY

          # File details for downloaded sources
          echo "## ðŸ“¦ Downloaded Files" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # USAspending files
          if [ "${{ needs.determine-source.outputs.usaspending }}" = "true" ] && [ "${{ needs.refresh-usaspending.result }}" = "success" ]; then
            echo "### ðŸ’° USAspending Data" >> $GITHUB_STEP_SUMMARY
            echo "**Recipients:**" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            aws s3 ls s3://${{ env.S3_BUCKET }}/raw/usaspending/recipient_lookup/ --recursive --human-readable --summarize | tail -10
            echo '```' >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "**NAICS Lookup:**" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            aws s3 ls s3://${{ env.S3_BUCKET }}/raw/usaspending/naics_lookup/ --recursive --human-readable --summarize | tail -10
            echo '```' >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          fi

          # USPTO files
          if [ "${{ needs.determine-source.outputs.uspto }}" = "true" ] && [ "${{ needs.refresh-uspto.result }}" = "success" ]; then
            echo "### ðŸ“œ USPTO Patent Data" >> $GITHUB_STEP_SUMMARY

            echo "**PatentsView:**" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            aws s3 ls s3://${{ env.S3_BUCKET }}/uspto/patentsview/ --recursive --human-readable | tail -5
            echo '```' >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY

            echo "**Assignments:**" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            aws s3 ls s3://${{ env.S3_BUCKET }}/uspto/assignments/ --recursive --human-readable | tail -5
            echo '```' >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY

            echo "**AI Patents:**" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            aws s3 ls s3://${{ env.S3_BUCKET }}/uspto/ai-patents/ --recursive --human-readable | tail -5
            echo '```' >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          fi

          # Statistics
          echo "## ðŸ“ˆ Statistics" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Total jobs:** $TOTAL" >> $GITHUB_STEP_SUMMARY
          echo "- **Successful:** $SUCCESS_COUNT âœ…" >> $GITHUB_STEP_SUMMARY
          echo "- **Failed:** $FAILED_COUNT âŒ" >> $GITHUB_STEP_SUMMARY
          echo "- **Skipped:** $SKIPPED_COUNT â­ï¸" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Final verdict
          if [ "$OVERALL_SUCCESS" = "true" ] && [ "$TOTAL" -gt 0 ]; then
            echo "## âœ… Overall Status: SUCCESS" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "All data refresh jobs completed successfully!" >> $GITHUB_STEP_SUMMARY
          elif [ "$TOTAL" -eq 0 ]; then
            echo "## âš ï¸ Overall Status: NO JOBS RUN" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "No data sources were selected for refresh." >> $GITHUB_STEP_SUMMARY
          else
            echo "## âŒ Overall Status: FAILURES DETECTED" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "âš ï¸ One or more data refresh jobs failed. Please review the detailed reports above and check the job logs." >> $GITHUB_STEP_SUMMARY
          fi

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "---" >> $GITHUB_STEP_SUMMARY
          echo "**Workflow completed at:** $(date -u '+%Y-%m-%d %H:%M:%S UTC')" >> $GITHUB_STEP_SUMMARY
          echo "**S3 Bucket:** \`${{ env.S3_BUCKET }}\`" >> $GITHUB_STEP_SUMMARY

  run-pipeline:
    name: Run ETL Pipeline
    needs:
      [
        determine-source,
        refresh-sbir,
        refresh-usaspending,
        refresh-uspto,
        summary,
      ]
    if: |
      always() &&
      (github.event.inputs.trigger_dagster != 'false') &&
      (needs.refresh-sbir.result == 'success' || needs.refresh-usaspending.result == 'success' || needs.refresh-uspto.result == 'success')
    runs-on: ubuntu-latest
    timeout-minutes: 60
    steps:
      - uses: actions/checkout@v6

      - name: Configure AWS credentials
        uses: ./.github/actions/setup-aws-credentials
        with:
          role-arn: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Python and UV
        uses: ./.github/actions/setup-python-uv
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: uv sync

      - name: Run SBIR pipeline
        if: needs.determine-source.outputs.sbir == 'true' && needs.refresh-sbir.result == 'success'
        env:
          # Use test or production Neo4j based on environment input (default: production for scheduled runs)
          NEO4J_URI: ${{ github.event.inputs.environment == 'test' && secrets.NEO4J_AURA_TEST_URI || secrets.NEO4J_AURA_URI }}
          NEO4J_USER: neo4j
          NEO4J_PASSWORD: ${{ github.event.inputs.environment == 'test' && secrets.NEO4J_AURA_TEST_PASSWORD || secrets.NEO4J_AURA_PASSWORD }}
          SBIR_ETL__PIPELINE__ENVIRONMENT: production
          S3_BUCKET: ${{ env.S3_BUCKET }}
        run: |
          echo "## ðŸŽ¯ SBIR Pipeline" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          uv run dagster job execute \
            -m src.definitions \
            -j sbir_weekly_refresh_job \
            2>&1 | tee sbir_output.txt

          if [ ${PIPESTATUS[0]} -eq 0 ]; then
            echo "âœ… **SBIR pipeline completed**" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY

            # Extract key metrics
            EXTRACTED=$(grep -o "Extracted [0-9]* records" sbir_output.txt | head -1 || echo "")
            VALIDATED=$(grep -o "Validation complete" sbir_output.txt | head -1 || echo "")
            QUALITY=$(grep -o "Quality check result: [A-Z]*" sbir_output.txt | head -1 || echo "")

            if [ -n "$EXTRACTED" ] || [ -n "$VALIDATED" ] || [ -n "$QUALITY" ]; then
              echo "**Key Metrics:**" >> $GITHUB_STEP_SUMMARY
              [ -n "$EXTRACTED" ] && echo "- $EXTRACTED" >> $GITHUB_STEP_SUMMARY
              [ -n "$VALIDATED" ] && echo "- $VALIDATED" >> $GITHUB_STEP_SUMMARY
              [ -n "$QUALITY" ] && echo "- $QUALITY" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
            fi

            echo "<details><summary>ðŸ“‹ Full Pipeline Output</summary>" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            tail -100 sbir_output.txt >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            echo "</details>" >> $GITHUB_STEP_SUMMARY
          else
            echo "âŒ **SBIR pipeline failed**" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            tail -50 sbir_output.txt >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            exit 1
          fi

      - name: Validate USAspending data availability
        if: needs.determine-source.outputs.usaspending == 'true' && needs.refresh-usaspending.result == 'success'
        id: validate-usaspending
        run: |
          echo "## ðŸ” Validating USAspending Data" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Check if extraction completed (look for completion marker or recent files)
          RECIPIENT_FILE=$(aws s3 ls "s3://${{ env.S3_BUCKET }}/raw/usaspending/recipient_lookup/" --recursive | tail -1 || echo "")
          NAICS_FILE=$(aws s3 ls "s3://${{ env.S3_BUCKET }}/raw/usaspending/naics_lookup/" --recursive | tail -1 || echo "")

          if [ -z "$RECIPIENT_FILE" ] || [ -z "$NAICS_FILE" ]; then
            echo "âŒ **USAspending data not ready**" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "Batch job may still be running. Check:" >> $GITHUB_STEP_SUMMARY
            echo "- [AWS Batch Console](https://console.aws.amazon.com/batch/home?region=${{ env.AWS_REGION }}#jobs)" >> $GITHUB_STEP_SUMMARY
            echo "- [CloudWatch Logs](https://console.aws.amazon.com/cloudwatch/home?region=${{ env.AWS_REGION }}#logsV2:log-groups/log-group//aws/batch/sbir-analytics-analysis)" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "Re-run this workflow after extraction completes." >> $GITHUB_STEP_SUMMARY
            exit 1
          fi

          echo "âœ… **USAspending data available**" >> $GITHUB_STEP_SUMMARY
          echo "- recipient_lookup: $(echo $RECIPIENT_FILE | awk '{print $4}')" >> $GITHUB_STEP_SUMMARY
          echo "- naics_lookup: $(echo $NAICS_FILE | awk '{print $4}')" >> $GITHUB_STEP_SUMMARY

      - name: Run USAspending enrichment
        if: needs.determine-source.outputs.usaspending == 'true' && steps.validate-usaspending.outcome == 'success'
        env:
          SBIR_ETL__PIPELINE__ENVIRONMENT: production
          S3_BUCKET: ${{ env.S3_BUCKET }}
        shell: bash
        run: |
          echo "## ðŸ’° USAspending Enrichment" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          uv run dagster job execute \
            -m src.definitions \
            -j usaspending_iterative_enrichment_job \
            2>&1 | tee usaspending_output.txt

          EXIT_CODE=${PIPESTATUS[0]}
          if [ $EXIT_CODE -eq 0 ]; then
            echo "âœ… **USAspending enrichment completed**" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY

            # Extract key metrics
            ENRICHED=$(grep -o "enriched [0-9]* records" usaspending_output.txt | head -1 || echo "")
            MATCHED=$(grep -o "[0-9]*% matched" usaspending_output.txt | head -1 || echo "")

            if [ -n "$ENRICHED" ] || [ -n "$MATCHED" ]; then
              echo "**Key Metrics:**" >> $GITHUB_STEP_SUMMARY
              [ -n "$ENRICHED" ] && echo "- $ENRICHED" >> $GITHUB_STEP_SUMMARY
              [ -n "$MATCHED" ] && echo "- $MATCHED" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
            fi

            echo "<details><summary>ðŸ“‹ Full Enrichment Output</summary>" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            tail -100 usaspending_output.txt >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            echo "</details>" >> $GITHUB_STEP_SUMMARY
          else
            echo "âŒ **USAspending enrichment failed**" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            tail -50 usaspending_output.txt >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            exit 1
          fi

      - name: Run USPTO pipeline
        if: needs.determine-source.outputs.uspto == 'true' && needs.refresh-uspto.result == 'success'
        env:
          NEO4J_URI: ${{ github.event.inputs.environment == 'test' && secrets.NEO4J_AURA_TEST_URI || secrets.NEO4J_AURA_URI }}
          NEO4J_USER: neo4j
          NEO4J_PASSWORD: ${{ github.event.inputs.environment == 'test' && secrets.NEO4J_AURA_TEST_PASSWORD || secrets.NEO4J_AURA_PASSWORD }}
          SBIR_ETL__PIPELINE__ENVIRONMENT: production
          S3_BUCKET: ${{ env.S3_BUCKET }}
        run: |
          echo "## ðŸ“œ USPTO Pipeline" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          uv run dagster job execute \
            -m src.definitions \
            -j uspto_validation_job \
            2>&1 | tee uspto_output.txt

          if [ ${PIPESTATUS[0]} -eq 0 ]; then
            echo "âœ… **USPTO pipeline completed**" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY

            # Extract key metrics
            PATENTS=$(grep -o "Loaded [0-9]* patents" uspto_output.txt | head -1 || echo "")
            ASSIGNMENTS=$(grep -o "[0-9]* assignments" uspto_output.txt | head -1 || echo "")

            if [ -n "$PATENTS" ] || [ -n "$ASSIGNMENTS" ]; then
              echo "**Key Metrics:**" >> $GITHUB_STEP_SUMMARY
              [ -n "$PATENTS" ] && echo "- $PATENTS" >> $GITHUB_STEP_SUMMARY
              [ -n "$ASSIGNMENTS" ] && echo "- $ASSIGNMENTS" >> $GITHUB_STEP_SUMMARY
              echo "" >> $GITHUB_STEP_SUMMARY
            fi

            echo "<details><summary>ðŸ“‹ Full Pipeline Output</summary>" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            tail -100 uspto_output.txt >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            echo "</details>" >> $GITHUB_STEP_SUMMARY
          else
            echo "âŒ **USPTO pipeline failed**" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            tail -50 uspto_output.txt >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
          fi
