name: Transition MVP CI

on:
  pull_request:
    paths:
      - "src/assets/transition_assets.py"
      - "tests/integration/test_transition_mvp_chain.py"
      - "tests/unit/transition/test_transition_signals_and_boosts.py"
      - "docs/transition/**"
      - "Makefile"
      - ".github/workflows/transition-mvp-ci.yml"
  push:
    branches: [main]
    paths:
      - "src/assets/transition_assets.py"
      - "tests/integration/test_transition_mvp_chain.py"
      - "tests/unit/transition/test_transition_signals_and_boosts.py"
      - "docs/transition/**"
      - "Makefile"
      - ".github/workflows/transition-mvp-ci.yml"

permissions:
  contents: read

concurrency:
  group: transition-mvp-${{ github.ref }}
  cancel-in-progress: true

jobs:
  transition-mvp:
    name: Run Transition MVP (shim) and gate on validation summary
    runs-on: ubuntu-latest
    timeout-minutes: 20

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install Poetry
        run: |
          python -m pip install --upgrade pip
          pip install poetry

      - name: Install project dependencies (Poetry)
        run: |
          poetry --version
          poetry install --no-interaction --no-ansi

      - name: Run Transition MVP (shim)
        run: |
          make transition-mvp-run

      - name: Export precision audit sample (CSV)
        run: |
          poetry run python scripts/transition_precision_audit.py --export-csv reports/validation/vendor_resolution_audit_sample.csv

      - name: Upload precision audit sample
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: transition-mvp-precision-audit-sample
          path: reports/validation/vendor_resolution_audit_sample.csv
          if-no-files-found: warn
          retention-days: 7

      - name: Gate on validation summary
        id: gate
        run: |
          set -euo pipefail
          SUMMARY="reports/validation/transition_mvp.json"
          if [ ! -f "${SUMMARY}" ]; then
            echo "::error file=${SUMMARY}::Validation summary not found. Make sure the MVP run produced reports/validation/transition_mvp.json"
            exit 2
          fi

          python - <<'PY'
          import json, sys
          from pathlib import Path

          summary_path = Path("reports/validation/transition_mvp.json")
          data = json.loads(summary_path.read_text(encoding="utf-8"))

          gates = data.get("gates", {})
          cs = gates.get("contracts_sample", {})
          vr = gates.get("vendor_resolution", {})

          cs_pass = bool(cs.get("passed", False))
          vr_pass = bool(vr.get("passed", False))

          print("Transition MVP validation summary:")
          print(json.dumps(data, indent=2))

          failures = []
          if not cs_pass:
              failures.append("contracts_sample coverage gate failed")
          if not vr_pass:
              failures.append("vendor_resolution rate gate failed")

          if failures:
              for f in failures:
                  print(f"::error::{f}")
              sys.exit(1)
          else:
              print("All gates passed.")
          PY

      - name: Gate on evidence completeness
        run: |
          set -euo pipefail
          EV="data/processed/transitions_evidence.checks.json"
          if [ ! -f "${EV}" ]; then
            echo "::error file=${EV}::Evidence checks JSON not found. Ensure transition_evidence_v1 ran."
            exit 2
          fi
          python - <<'PY'
          import json, sys
          from pathlib import Path
          p = Path("data/processed/transitions_evidence.checks.json")
          data = json.loads(p.read_text(encoding="utf-8"))
          comp = (data.get("completeness") or {})
          complete = bool(comp.get("complete", False))
          print("Evidence checks:", json.dumps(comp, indent=2))
          if not complete:
              th = comp.get("threshold")
              ca = comp.get("candidates_above_threshold")
              er = comp.get("evidence_rows_for_above_threshold")
              print(f"::error::Evidence completeness gate failed: {er}/{ca} candidates at â‰¥{th}")
              sys.exit(1)
          print("Evidence completeness gate passed.")
          PY

      - name: Gate on analytics checks
        run: |
          set -euo pipefail
          AC="data/processed/transition_analytics.checks.json"
          if [ ! -f "${AC}" ]; then
            echo "::error file=${AC}::Analytics checks JSON not found. Ensure transition_analytics ran."
            exit 2
          fi
          python - <<'PY'
          import json, os, sys
          from pathlib import Path

          p = Path("data/processed/transition_analytics.checks.json")
          data = json.loads(p.read_text(encoding="utf-8"))

          award = data.get("award_transition_rate") or {}
          company = data.get("company_transition_rate") or {}
          a_den = int(award.get("denominator") or 0)
          c_den = int(company.get("denominator") or 0)
          a_rate = float(award.get("rate") or 0.0)
          c_rate = float(company.get("rate") or 0.0)

          # Basic sanity checks
          denom_ok = (a_den > 0) and (c_den > 0)
          rate_bounds_ok = (0.0 <= a_rate <= 1.0) and (0.0 <= c_rate <= 1.0)

          # Optional minimum thresholds from env
          def _env_float(key, default):
              try:
                  return float(os.environ.get(key, str(default)))
              except Exception:
                  return default

          min_award_rate = _env_float("SBIR_ETL__TRANSITION__ANALYTICS__MIN_AWARD_RATE", 0.0)
          min_company_rate = _env_float("SBIR_ETL__TRANSITION__ANALYTICS__MIN_COMPANY_RATE", 0.0)
          min_ok = (a_rate >= min_award_rate) and (c_rate >= min_company_rate)

          print("Analytics checks:", json.dumps({
              "award": {"denominator": a_den, "rate": a_rate, "min_rate": min_award_rate},
              "company": {"denominator": c_den, "rate": c_rate, "min_rate": min_company_rate},
              "sanity": {"denominators_positive": denom_ok, "rates_within_0_1": rate_bounds_ok},
          }, indent=2))

          if not denom_ok:
              print("::error::Analytics gate failed: zero denominators (award or company).")
              sys.exit(1)
          if not rate_bounds_ok:
              print("::error::Analytics gate failed: rates outside [0,1].")
              sys.exit(1)
          if not min_ok:
              print(f"::error::Analytics gate failed: rates below minimums "
                    f"(award: {a_rate:.2%} < {min_award_rate:.2%} "
                    f"or company: {c_rate:.2%} < {min_company_rate:.2%}).")
              sys.exit(1)

          print("Analytics checks gate passed.")
          PY

      - name: Upload validation summary
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: transition-mvp-validation
          path: |
            reports/validation/transition_mvp.json
          if-no-files-found: warn
          retention-days: 7

      - name: Upload processed artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: transition-mvp-artifacts
          path: |
            data/processed/vendor_resolution.*
            data/processed/transitions.*
            data/processed/transitions_evidence.*
            data/processed/transition_analytics.*
            data/processed/contracts_sample.*
          if-no-files-found: warn
          retention-days: 7
