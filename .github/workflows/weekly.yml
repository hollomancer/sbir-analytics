name: Weekly Comprehensive Tests

on:
  schedule:
    - cron: "0 2 * * 0"   # 02:00 UTC Sunday
  workflow_dispatch:
    inputs:
      test_level:
        description: 'Test level'
        required: false
        default: comprehensive
        type: choice
        options:
          - standard
          - comprehensive

permissions:
  contents: write
  pull-requests: write
  actions: read
  checks: read

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  PYTHON_VERSION: "3.11"
  NEO4J_IMAGE: "neo4j:5"
  NEO4J_USERNAME: "neo4j"
  NEO4J_PASSWORD: "password"  # pragma: allowlist secret
  REPAIR_BRANCH_PREFIX: "bot/ci-fix"

jobs:
  tests:
    name: Extended Test Suites
    runs-on: ubuntu-latest
    timeout-minutes: 30
    continue-on-error: true
    strategy:
      fail-fast: false
      matrix:
        include:
          - suite: slow-unit
            pytest_target: "tests/unit/"
            pytest_args: '-m "slow" -v'
            needs_neo4j: false
          - suite: integration
            pytest_target: "tests/integration/"
            pytest_args: '-m "integration and not slow" -v'
            needs_neo4j: true
          - suite: e2e-smoke
            pytest_target: "tests/e2e/"
            pytest_args: '-m "e2e and not weekly" -v'
            needs_neo4j: false
    steps:
      - uses: actions/checkout@v6

      - name: Setup Python and UV
        uses: ./.github/actions/setup-python-uv
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          install-dev-deps: "true"
          cache-venv: "true"
          install-pyreadstat: "true"

      - name: Start Neo4j service
        if: matrix.needs_neo4j == true
        run: |
          docker run -d --name weekly-neo4j \
            -e NEO4J_AUTH=${{ env.NEO4J_USERNAME }}/${{ env.NEO4J_PASSWORD }} \
            -p 7687:7687 -p 7474:7474 \
            ${{ env.NEO4J_IMAGE }}
          for i in {1..12}; do
            if curl -s -f -o /dev/null http://localhost:7474; then
              echo "Neo4j is ready"
              break
            fi
            echo "Waiting for Neo4j... ($i/12)"
            sleep 5
          done

      - name: Run ${{ matrix.suite }} tests
        run: uv run pytest ${{ matrix.pytest_target }} ${{ matrix.pytest_args }}

      - name: Stop Neo4j service
        if: always() && matrix.needs_neo4j == true
        run: |
          docker stop weekly-neo4j || true
          docker rm weekly-neo4j || true

  diagnose:
    name: Diagnose Test Failures
    needs: tests
    runs-on: ubuntu-latest
    timeout-minutes: 10
    if: always()
    outputs:
      failed: ${{ steps.check.outputs.failed }}
    steps:
      - name: Check test results
        id: check
        run: |
          if [ "${{ needs.tests.result }}" != "success" ]; then
            echo "failed=true" >> $GITHUB_OUTPUT
          else
            echo "failed=false" >> $GITHUB_OUTPUT
          fi

  attempt_repair:
    name: Attempt Auto-Repair
    needs: diagnose
    if: needs.diagnose.outputs.failed == 'true'
    runs-on: ubuntu-latest
    timeout-minutes: 30
    outputs:
      changed: ${{ steps.commit.outputs.changed }}
    steps:
      - uses: actions/checkout@v6

      - name: Create repair branch
        id: branch
        run: |
          branch="${REPAIR_BRANCH_PREFIX}/${GITHUB_SHA::7}"
          git switch -c "$branch"
          echo "branch=$branch" >> $GITHUB_OUTPUT

      - name: Setup Python and UV
        uses: ./.github/actions/setup-python-uv
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          install-dev-deps: "true"
          cache-venv: "true"

      - name: Autofix (black + isort)
        run: |
          uv run black . || true
          uv run isort . || true

      - name: Commit changes if any
        id: commit
        run: |
          git add -A
          if git diff --cached --quiet; then
            echo "changed=false" >> $GITHUB_OUTPUT
          else
            git -c user.name="ci-bot" -c user.email="actions@users.noreply.github.com" \
              commit -m "ci: weekly auto-repair (lint/format)"
            echo "changed=true" >> $GITHUB_OUTPUT
          fi

      - name: Open PR with fixes
        if: steps.commit.outputs.changed == 'true'
        uses: peter-evans/create-pull-request@v6
        with:
          branch: ${{ steps.branch.outputs.branch }}
          base: main
          delete-branch: true
          title: "CI: weekly auto-repair"
          body: |
            ## Auto-repair from weekly tests
            Applied safe formatting fixes.
            Review and merge if tests pass.
          labels: ci:autofix-candidate,bot
          draft: true

  fallback_issue:
    name: Open Issue if No Fix
    needs: [diagnose, attempt_repair]
    if: |
      needs.diagnose.outputs.failed == 'true' &&
      (needs.attempt_repair.result == 'skipped' ||
       needs.attempt_repair.outputs.changed == 'false')
    runs-on: ubuntu-latest
    steps:
      - uses: actions/github-script@v7
        with:
          script: |
            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `Weekly CI failure: ${context.sha.substring(0,7)}`,
              body: `**What failed**\nWeekly tests failed. See workflow artifacts.\n\n**Action needed**\nPropose fix in a PR.`,
              labels: ["ci:triage","bot"]
            })

  comprehensive-tests:
    name: Comprehensive Test Suite
    runs-on: ubuntu-latest
    timeout-minutes: 120
    if: github.event.schedule == '0 2 * * 0' || github.event.inputs.test_level == 'comprehensive'
    steps:
      - uses: actions/checkout@v6

      - name: Setup Python and UV
        uses: ./.github/actions/setup-python-uv
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          install-dev-deps: "true"
          cache-venv: "true"
          install-pyreadstat: "true"

      - name: Setup Neo4j service
        uses: ./.github/actions/setup-neo4j-service
        with:
          neo4j-image: ${{ env.NEO4J_IMAGE }}
          neo4j-username: ${{ env.NEO4J_USERNAME }}
          neo4j-password: ${{ env.NEO4J_PASSWORD }}

      - name: Wait for Neo4j
        uses: ./.github/actions/wait-for-neo4j
        with:
          neo4j-uri: "bolt://localhost:7687"
          neo4j-username: ${{ env.NEO4J_USERNAME }}
          neo4j-password: ${{ env.NEO4J_PASSWORD }}
          timeout-seconds: "60"

      - name: Run comprehensive test suite
        env:
          NEO4J_URI: "bolt://localhost:7687"
          NEO4J_USER: ${{ env.NEO4J_USERNAME }}
          NEO4J_PASSWORD: ${{ env.NEO4J_PASSWORD }}
          USE_REAL_SBIR_DATA: "1"
        run: |
          uv run pytest \
            -m "e2e or real_data or weekly" \
            --cov=src \
            --cov-report=html \
            --cov-report=xml \
            --cov-report=term \
            -n auto \
            --timeout=300 \
            -v
        timeout-minutes: 90

      - name: Upload coverage reports
        if: always()
        uses: codecov/codecov-action@v5
        with:
          files: ./coverage.xml
          flags: weekly-comprehensive
          name: weekly-comprehensive-coverage

      - name: Upload HTML coverage report
        if: always()
        uses: actions/upload-artifact@v5
        with:
          name: weekly-coverage-report
          path: htmlcov/
          retention-days: 30

  real-data-validation:
    name: Real Data Validation
    runs-on: ubuntu-latest
    timeout-minutes: 60
    if: github.event.schedule == '0 2 * * 0' || github.event.inputs.test_level == 'comprehensive'
    steps:
      - uses: actions/checkout@v6

      - name: Setup Python and UV
        uses: ./.github/actions/setup-python-uv
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          install-dev-deps: "true"
          cache-venv: "true"
          install-pyreadstat: "true"

      - name: Run validation scripts
        run: uv run python tests/validation/test_categorization_validation.py

      - name: Upload validation reports
        if: always()
        uses: actions/upload-artifact@v5
        with:
          name: validation-reports
          path: |
            validation-reports/
            *.csv
          retention-days: 30

  performance-profiling:
    name: Performance Profiling
    runs-on: ubuntu-latest
    timeout-minutes: 45
    if: github.event.schedule == '0 2 * * 0' || github.event.inputs.test_level == 'comprehensive'
    steps:
      - uses: actions/checkout@v6

      - name: Setup Python and UV
        uses: ./.github/actions/setup-python-uv
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          install-dev-deps: "true"
          cache-venv: "true"

      - name: Run performance benchmarks
        run: |
          uv run pytest \
            -m "slow" \
            --benchmark-only \
            --benchmark-json=benchmark-results.json \
            -v

      - name: Upload benchmark results
        if: always()
        uses: actions/upload-artifact@v5
        with:
          name: performance-benchmarks
          path: benchmark-results.json
          retention-days: 90
